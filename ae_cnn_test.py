import tensorflow as tf
from data_reader import *
import numpy as np
from uncompress import *
import os
from ae import *

slim = tf.contrib.slim

# def log(message,file_path=os.path.join('cnn_logs_8','log.txt')):

#     print message
#     f1=open(file_path, 'a+')
#     f1.write(message)
#     f1.close()



def lrelu(alpha):
    def op(inputs):
        return tf.maximum(alpha * inputs, inputs, name='leaky_relu')
    return op

def conv_net(input):

    with slim.arg_scope([slim.conv2d, slim.fully_connected], #using scope to avoid mentioning the paramters repeatdely
                                        activation_fn=lrelu(0.005),
                                        weights_initializer=tf.truncated_normal_initializer(0.0, 0.01),
                                        weights_regularizer=slim.l2_regularizer(0.0005)):
	#net = slim.max_pool2d(input,(1,4),(1,4), padding='VALID', scope='pool_0')
	

        net = slim.conv2d(input, 512, (3,1357), 1, padding='VALID', scope='cnn_conv_1')
                        
        net = slim.max_pool2d(net, (4,1),4, padding='VALID', scope='cnn_pool_2')
                        
        net = slim.conv2d(net, 512, (5,1), 1, scope='cnn_conv_3')

        net = slim.max_pool2d(net, (4,1),4, padding='VALID', scope='cnn_pool_4')

        net = slim.flatten(net, scope='cnn_flatten_5')

        # net = slim.fully_connected(net, 1024, scope='fc_6',activation_fn=tf.nn.softmax)
	
        # net = slim.fully_connected(net, 256, scope='fc_7',activation_fn=tf.nn.softmax)

        net = slim.fully_connected(net, 2, scope='cnn_fc_8',activation_fn=tf.nn.softmax)
	
	# net = slim.fully_connected(net, 4096, scope='fc5')
	# net = slim.dropout(net, 0.5, scope='dropout6')
	# net = slim.fully_connected(net, 4096, scope='fc7')
	# net = slim.dropout(net, 0.5, scope='dropout8')
	# net = slim.fully_connected(net,2, activation_fn=None, scope='fc9')

    
    return net

def one_hot(batch_size,Y):

    B = np.zeros((batch_size,2))

    B[np.arange(batch_size),Y] = 1

    return B

if __name__=='__main__':

    # os.environ['CUDA_VISIBLE_DEVICES'] = '1'
    # x = compress(None,None,True)
    #print x
    # Training Parameters
    learning_rate = 0.00001
    

    ################################################################
    num_epoch = 1
    batch_size = 1
    display_step = 1
    input_size = 50
    num_classes = 2 

    X = tf.placeholder(tf.float32, [None, input_size,86796,1])

    reconstruction, compressed,_,_,_,_ = autoencoder(X)


    cnn_X = tf.placeholder(tf.float32, [None, input_size,1357,8])
    
    cnn_Y = tf.placeholder(tf.float32, [None, num_classes])

    cnn_prediction = conv_net(cnn_X)

    cnn_loss_op = slim.losses.softmax_cross_entropy(cnn_prediction,cnn_Y)


    cnn_optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)
    cnn_train_op = cnn_optimizer.minimize(cnn_loss_op)


    cnn_correct_pred = tf.equal(tf.argmax(cnn_prediction, 1), tf.argmax(cnn_Y, 1))
    cnn_accuracy = tf.reduce_mean(tf.cast(cnn_correct_pred, tf.float32))
    
    cnn_init = tf.global_variables_initializer()

    print 'loading test data...'

    test_data_X, test_data_Y = load_test_data()

    with tf.Session() as sess:

        print "Testing..."
        
        saver = tf.train.Saver()
        print saver._var_list
        #exit(0)
        
        # sess.run(cnn_init)

        # print 'restoring ae session'
        # saver.restore(sess, "ae_logs_1/save.ckpt")
        # print 'done loading'   


        print 'restoring session from ', "cnn_logs_ae/save.ckpt"
        saver.restore(sess, "cnn_logs_ae/save.ckpt")
        print 'done loading'
        # exit(0) 
        i = 0
        test_acc = 0.0
        for step in range(test_data_X.shape[0]/batch_size):
                batch_x, batch_y = test_data_X[step*batch_size:(step+1)*batch_size],\
                test_data_Y[step*batch_size:(step+1)*batch_size]

                i+=1

                batch_x = uncompress(batch_x,86796)
                batch_x = sess.run(compressed, feed_dict={X: batch_x})
                # print batch_y
                batch_y = one_hot(batch_size,batch_y)

                batch_y = np.repeat(batch_y,50,axis=0)

                # print batch_y

                assert(batch_x.shape[0]==batch_y.shape[0])

                acc = sess.run(cnn_accuracy, feed_dict={cnn_X: batch_x,cnn_Y: batch_y})
                test_acc += acc
                print "Test Accuracy = " + "{:.3f}".format(test_acc/i)
       